# 平均负载

平均负载是指单位时间内，系统处于 **可运行状态** 和 **不可中断状态** 的平均进程数。简单理解，就是平均**活跃进程数**。

* 可运行状态：进程正在或等待使用CPU
* 不可中断状态：进程正在等待硬件设备的I/O，是系统对进程和硬件设备的一种保护机制。

最理想的情况是，每个CPU上刚好运行着1个进程，也就是平均负载等于CPU的个数。假如平均负载是2，那么意味着：

* 单核CPU上，有一半的进程竞争不到CPU
* 双核CPU上，所有的CPU刚好被完全占用
* 4核CPU上，意味着CPU有50%的空闲（idle）

注意，这里的核指逻辑核数，比如超线程的双核CPU，相当于4核。

因此，当平均负载比CPU个数还大时，就出现了系统过载。

在生产环境中，一般推荐平均负载不要高于CPU数量的70%

### 区别CPU使用率

CPU使用率是单位时间内CPU繁忙情况的统计。而平均负载包括**正在使用CPU、等待CPU、等待IO**的进程。具体来说：

* CPU密集型进程，CPU使用率高，平均负载高
* I/O密集型进程，平均负载高，CPU使用率低
* 大量等待CPU的进程，平均负载高，CPU使用率也会比较高

## 案例分析

### 准备工具

linux系统，并安装以下两款工具：yum install stress sysstat

* stress:  linux系统压力测试工具
* sysstat：包含了常用的linux性能工具，这里用到它提供的两个命令：
  * mpstat:  多核CPU性能分析工具
  * pidstat: 进程性能分析工具，可实时查看cpu, 内存，I/O以及上下文切换等指标

### 场景一：CPU密集型进程

以root身份登录中断，在终端1执行如下命令：

```bash
stress --cpu 2 --timeout 600
# 产生2个进程，压测CPU 600秒, 具体命令参考 man stress说明
```

终端2执行uptime查看平均负载的变化情况

```bash
# watch 监测 -d 表示高亮显示变化的部分
watch -d uptime

Every 2.0s: uptime                                                               Wed Dec 26 20:39:47 2018

20:39:47 up 54 days,  2:56,  4 users,  load average: 0.93, 4.30, 3.23

```

终端3查看CPU使用率变化：

```shell
mpstat -P ALL 2 5  
# 每两秒刷新下所有CPU的统计报告，一共刷新显示显示5次。如果不指定最后一个5，那么将一直刷新。
```

```bash
mpstat -P ALL 2
Linux 3.10.0-693.11.1.el7.x86_64 (iz2zeap40j01vg100ifsf4z)      12/26/2018      _x86_64_        (2 CPU)

08:41:38 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:41:43 PM  all   33.56    0.00    2.01    0.00    0.00    0.00    0.00    0.00    0.00   64.43
08:41:43 PM    0   17.37    0.00    1.27    0.00    0.00    0.00    0.00    0.00    0.00   81.36
08:41:43 PM    1   92.19    0.00    6.25    0.00    0.00    0.00    0.00    0.00    0.00    1.56

# 其中一个CPU的使用率非常高， 但iowait为0，说明平均负载的升高是由CPU使用率高造成的。
```

使用查看导致CPU升高的进程:

```bash
pidstat -u 2 1 
# -u 报告CPU的使用率，2 每两秒，1 报告一次
```

```shell
07:57:34 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:57:39 PM     0         9    0.00    0.20    0.00    0.20     1  rcu_sched
07:57:39 PM     0       479  100.00    0.00    0.00  100.00     0  stress
07:57:39 PM     0      1586    0.00    0.20    0.00    0.20     0  aliyun-service
```

### 场景二：I/O 密集型进程

```bash
stress --io N --timeout 600
# 产生N个进程，模拟IO压力
```

### 场景三：大量进程的情况

```bash
stress --cpu 8  # 产生8个进程对CPU进行压测
```

由于系统只有两个CPU，因此系统处于严重过载状态：

uptime查看负载：1分钟平均负载慢慢飙升到 8.97

```bash
20:36:39 up 62 days,  2:53,  5 users,  load average: 8.97, 5.49, 2.86
```

mpstat查看CPU统计数据，可以看到CPU 0 和 1 都满了

```bash
Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
Average:     all  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
Average:       0   98.96    0.00    0.52    0.00    0.00    0.52    0.00    0.00    0.00    0.00
Average:       1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
```

pidstat 查看系统任务统计（一个任务相当于一个进程）

```bash
Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
Average:        0      1286    0.49    0.00    0.00    0.49     -  java
Average:        0      3270   23.15    0.00    0.00   23.15     -  stress
Average:        0      3271   25.62    0.00    0.00   25.62     -  stress
Average:        0      3272   23.65    0.00    0.00   23.65     -  stress
Average:        0      3273   27.09    0.00    0.00   27.09     -  stress
Average:        0      3274   25.12    0.00    0.00   25.12     -  stress
Average:        0      3275   21.67    0.00    0.00   21.67     -  stress
Average:        0      3276   25.62    0.00    0.00   25.62     -  stress
Average:        0      3277   23.15    0.00    0.00   23.15     -  stress
Average:        0      6453    0.49    0.00    0.00    0.49     -  dockerd
Average:        0     30783    0.00    0.49    0.00    0.49     -  celery
```

# CPU上下文切换

当活跃进程数大于CPU数量时，会出现竞争，CPU需要轮流执行这些进程，于是产生CPU上下文切换，这个切换是有开销的，会导致负载升高。

## 查看CPU上下文切换

vmstat 用来查看虚拟内存，也可以查看一些CPU总体的上下文切换情况。

```bash
vmstat 5 1   
# 5秒钟输出一组数据
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 124980 170900 1002128    0    0    22    14    1    1  2  1 97  0  0
 0  0      0 124740 170900 1002144    0    0     0  1820 1074 1195  2  1 97  0  0
```

有用参数

* cs: context switch 每秒钟上下文切换次数
* in：interrupt  每秒钟系统中断次数
* r：running or runnable 就绪队列的长度（运行中，等待运行的进程数）
* b：blocked 处于不可中断的进程数（进程正在等待硬件设备的I/O）

使用`pidstat -w`查看每个进程的详细情况：

```bash
pidstat -w 5

Average:      UID       PID   cswch/s nvcswch/s  Command
Average:        0         3      0.40      0.00  ksoftirqd/0
Average:        0         9     57.49      0.00  rcu_sched
Average:        0        10      0.20      0.00  watchdog/0
```

参数：

* cswch/s：voluntary context switches 自愿上下文切换，指进程无法获取所需的自愿（I/O， 内存等系统资源不足时），发生自愿的上下文切换。
* nvcswch/s: non voluntary context switches 非自愿的上下文切换，进程的时间片到期，被系统强制发生的切换。当大量进程争抢CPU时，就会发生非自愿的上下文切换

## 模拟测试

安装**sysbench**，多线程基准测试工具：yum install sysbench sysstat

输入如下命令模拟系统多线程调度的瓶颈：

```bash
sysbench --threads=10 --max-time=300 threads run
# 运行10个线程，5分钟
```

新开一个终端，查看上下文切换情况：

```bash
vmstat 1 1 # 每秒刷新一次

procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 9  0      0 296684 171112 1201540    0    0    21    14    2    2  2  1 97  0  0
 6  0      0 296560 171112 1201540    0    0     0     0 3081 1947126 12 88  0  0  0
 6  0      0 296436 171112 1201540    0    0     0     0 3192 2086130 14 86  1  0  0
```

可以发现如下特点：

* r 就绪队列，长度达到9，超过系统CPU个数（2个）
* in 终端次数达到3000次
* cs 上下文切换次数达到每秒200万次
* us + sy 的cpu使用率加起来达到100%，其中几乎都被sys占用，说明CPU主要被内核占用了

综合以上数据，得出结论：系统的就绪队列过长，导致了大量的上下文切换，大量上下文切换又导致了CPU的占用率升高。

下面我们通过pidstat命令来查看具体情况：

```bash
pidstat -wu 1 2
# -w 输出切换指标  -u 输出CPU使用率  1秒刷新一次，一共刷新2次

08:58:30 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
08:58:31 PM     0      1286    1.00    0.00    0.00    1.00     1  java
08:58:31 PM     0      3871    1.00    1.00    0.00    2.00     1  AliYunDun
08:58:31 PM   999      7145    1.00    0.00    0.00    1.00     1  redis-server
08:58:31 PM     0      9626    1.00    0.00    0.00    1.00     1  celery
08:58:31 PM     0      9627    1.00    0.00    0.00    1.00     0  celery
08:58:31 PM     0     11201   31.00  100.00    0.00  100.00     1  sysbench  # 100% CPU

08:58:30 PM   UID       PID   cswch/s nvcswch/s  Command
08:58:31 PM     0         9     65.00      0.00  rcu_sched
08:58:31 PM     0        13      2.00      0.00  ksoftirqd/1
08:58:31 PM     0       266      3.00      0.00  kworker/0:1H
08:58:31 PM     0       271      4.00      0.00  jbd2/vda1-8
08:58:31 PM     0      1267     10.00      0.00  wrapper
08:58:31 PM     0      1439     12.00      0.00  PM2
# ...

08:58:31 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
08:58:32 PM     0     11201   30.00  100.00    0.00  100.00     1  sysbench
08:58:32 PM     0     11213    0.00    1.00    0.00    1.00     1  pidstat

08:58:31 PM   UID       PID   cswch/s nvcswch/s  Command
08:58:32 PM     0         9     58.00      0.00  rcu_sched
08:58:32 PM     0        13      1.00      0.00  ksoftirqd/1
08:58:32 PM     0       482      1.00      0.00  irqbalance
08:58:32 PM     0      1267     10.00      0.00  wrapper
08:58:32 PM     0      1439     12.00      0.00  PM2
# ...
```

观察输出，发现sysbench确实导致了CPU使用率升高，但是上下文切换来自其他进程，并且数量加起来都不到3位数，那为什么vmstat中观察到了200万了，这是为什么？

这是因为线程是系统调度的基本单位，而且sysbench模拟的是线程调度。因此，只需加一个`-t`参数，就可以查看线程切换了：

```bash
pidstat -wut 1 3

09:09:18 PM   UID      TGID       TID    %usr %system  %guest    %CPU   CPU  Command
09:09:19 PM     0      1267         -    1.00    0.00    0.00    1.00     1  wrapper
09:09:19 PM     0         -      3818    1.00    0.00    0.00    1.00     0  |__AliYunDunUpdate
09:09:19 PM     0         -      3872    1.00    0.00    0.00    1.00     0  |__AliYunDun
09:09:19 PM     0     11290         -   34.00  100.00    0.00  100.00     1  sysbench
09:09:19 PM     0         -     11291    4.00   15.00    0.00   19.00     0  |__sysbench
09:09:19 PM     0         -     11292    3.00   16.00    0.00   19.00     1  |__sysbench
09:09:19 PM     0         -     11293    3.00   15.00    0.00   18.00     1  |__sysbench
09:09:19 PM     0         -     11294    3.00   14.00    0.00   17.00     0  |__sysbench
09:09:19 PM     0         -     11295    3.00   17.00    0.00   20.00     0  |__sysbench
09:09:19 PM     0         -     11296    4.00   19.00    0.00   23.00     0  |__sysbench
09:09:19 PM     0         -     11297    3.00   16.00    0.00   19.00     0  |__sysbench
09:09:19 PM     0         -     11298    4.00   16.00    0.00   20.00     0  |__sysbench
09:09:19 PM     0         -     11299    3.00   15.00    0.00   18.00     0  |__sysbench
09:09:19 PM     0         -     11300    3.00   15.00    0.00   18.00     0  |__sysbench
09:09:19 PM     0     11302         -    0.00    1.00    0.00    1.00     1  pidstat
09:09:19 PM     0         -     11302    0.00    1.00    0.00    1.00     1  |__pidstat

09:09:18 PM   UID      TGID       TID   cswch/s nvcswch/s  Command
# ...
09:09:19 PM     0      9631         -      5.00      0.00  celery
09:09:19 PM     0         -      9631      5.00      0.00  |__celery
09:09:19 PM     0         -      9668      2.00      0.00  |__celery
09:09:19 PM     0         -      9669      2.00      0.00  |__celery
09:09:19 PM     0      9632         -      4.00      0.00  celery
09:09:19 PM     0         -      9632      4.00      0.00  |__celery
09:09:19 PM     0         -      9674      2.00      0.00  |__celery
09:09:19 PM     0         -      9675      2.00      0.00  |__celery
09:09:19 PM     0     11267         -      1.00      0.00  kworker/1:1
09:09:19 PM     0         -     11267      1.00      0.00  |__kworker/1:1
09:09:19 PM     0         -     11291  22986.00 175294.00  |__sysbench
09:09:19 PM     0         -     11292  28215.00 170894.00  |__sysbench
09:09:19 PM     0         -     11293  23272.00 138182.00  |__sysbench
09:09:19 PM     0         -     11294  34244.00 151715.00  |__sysbench
09:09:19 PM     0         -     11295  31714.00 167521.00  |__sysbench
09:09:19 PM     0         -     11296  20949.00 194500.00  |__sysbench
09:09:19 PM     0         -     11297  30983.00 185232.00  |__sysbench
09:09:19 PM     0         -     11298  28358.00 172171.00  |__sysbench
09:09:19 PM     0         -     11299  29662.00 159875.00  |__sysbench
09:09:19 PM     0         -     11300  27557.00 148900.00  |__sysbench
09:09:19 PM     0     11302         -      2.00      4.00  pidstat
09:09:19 PM     0         -     11302      2.00      4.00  |__pidstat
# ...
```

从上述输出可以观察到，sysbench的线程的大量切换。

另外，如果要查看中断次数，可以读取这个文件`/proc/interrupts`：

> /proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts 就是这种通信机制的一部分，提供了一个只读的中断使用情况。

```bash
watch -d cat /proc/interrupts
# 高亮显示中断文件的变动部分

Every 2.0s: cat /proc/interrupts                                        Thu Jan 10 21:20:13 2019

           CPU0       CPU1
  0:         20          0   IO-APIC-edge      timer
  1:         10          0   IO-APIC-edge      i8042
  6:          3          0   IO-APIC-edge      floppy
  8:          0          0   IO-APIC-edge      rtc0
  9:          0          0   IO-APIC-fasteoi   acpi
 10:          0          0   IO-APIC-fasteoi   virtio4
 11:         35          0   IO-APIC-fasteoi   uhci_hcd:usb1
 12:         15          0   IO-APIC-edge      i8042
 14:          0          0   IO-APIC-edge      ata_piix
 15:    5756484          0   IO-APIC-edge      ata_piix
 24:          0          0   PCI-MSI-edge      virtio2-config
 25:    2673089    5845758   PCI-MSI-edge      virtio2-req.0
 26:          1          0   PCI-MSI-edge      virtio0-config
 27:    1868713   37408103   PCI-MSI-edge      virtio0-input.0
 28:     349576   44643775   PCI-MSI-edge      virtio0-output.0
 29:          0          0   PCI-MSI-edge      virtio3-config
 30:     326128          0   PCI-MSI-edge      virtio3-req.0
 31:          0          0   PCI-MSI-edge      virtio1-config
 32:         22          0   PCI-MSI-edge      virtio1-virtqueues
NMI:          0          0   Non-maskable interrupts
LOC: 2924265642 2872116981   Local timer interrupts
SPU:          0          0   Spurious interrupts
PMI:          0          0   Performance monitoring interrupts
IWI:   60559294   62135237   IRQ work interrupts
RTR:          0          0   APIC ICR read retries
RES:  296793417  297917656   Rescheduling interrupts
CAL:   18746994     956271   Function call interrupts
TLB:    5927981    5878741   TLB shootdowns
TRM:          0          0   Thermal event interrupts
THR:          0          0   Threshold APIC interrupts
DFR:          0          0   Deferred Error APIC interrupts
MCE:          0          0   Machine check exceptions
```

从中可以观察到，以下两个参数在不断变化

*  Local timer interrupts
*  Rescheduling interrupts  重新调度中断（RES），表示唤醒空闲状态的CPU来调度新的任务运行，这是多处理器系统中，调度器用来分散任务到不同CPU的机制

## 结论

每秒上下文切换次数的大小，取决于CPU性能，一般来说，切换稳定，数值从百到万以内，都算正常：

* cswch/s 切换多，说明进程在等待资源，可能发生了I/O等其他问题
* nvcswch/sq 切换多，说明进程被强制调度，也就是争抢CPU，说明CPU有瓶颈
* 中断次数多了，说明CPU被中断程序占用，具体可以分析 /proc/interrupts文件